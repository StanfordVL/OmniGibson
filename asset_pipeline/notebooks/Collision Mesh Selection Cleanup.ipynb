{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846c778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"D:\\ig_pipeline\")\n",
    "\n",
    "from b1k_pipeline.utils import parse_name, get_targets, PIPELINE_ROOT\n",
    "\n",
    "files = []\n",
    "for fn in [PIPELINE_ROOT / \"cad\" / tgt / \"artifacts/collision_selection.json\" for tgt in get_targets(\"combined\")]:\n",
    "    with open(fn) as f:\n",
    "        files.append((fn, json.load(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d2e747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_cats = {}\n",
    "base_link_shows_w_name = {}\n",
    "for fn in [PIPELINE_ROOT / \"cad\" / tgt / \"artifacts/object_list.json\" for tgt in get_targets(\"combined\")]:\n",
    "    with open(fn) as f:\n",
    "        data = json.load(f)\n",
    "        for obj in data[\"provided_objects\"]:\n",
    "            cat, model = obj.split(\"-\")\n",
    "            if model in canonical_cats:\n",
    "                print(f\"{fn} {obj} previously seen as {canonical_cats[model]}\")\n",
    "            canonical_cats[model] = cat\n",
    "            \n",
    "        for mn in data[\"meshes\"]:\n",
    "            m = parse_name(mn)\n",
    "            if m.group(\"bad\"):\n",
    "                continue\n",
    "            if int(m.group(\"instance_id\")) != 0:\n",
    "                continue\n",
    "            model = m.group(\"model_id\")\n",
    "            if m.group(\"link_name\") in (None, \"\", \"base_link\"):\n",
    "                shows_w_name = m.group(\"link_name\") == \"base_link\"\n",
    "                assert model not in base_link_shows_w_name, model\n",
    "                base_link_shows_w_name[model] = shows_w_name\n",
    "                \n",
    "        canonical_cat_keys = set(canonical_cats.keys())\n",
    "        blswn_keys = set(base_link_shows_w_name.keys())\n",
    "        assert canonical_cat_keys == blswn_keys, [f\"{canonical_cats[k]}-{k}\" for k in canonical_cat_keys - blswn_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41445dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "for fn, all_selections in files:\n",
    "    print()\n",
    "    grouped_selections = collections.defaultdict(set)\n",
    "    for k, v in all_selections.items():\n",
    "        m = parse_name(k)\n",
    "        cat = m[\"category\"]\n",
    "        model = m[\"model_id\"]\n",
    "        link = m[\"link_name\"]\n",
    "        if model not in canonical_cats:\n",
    "            continue\n",
    "        if (link in (None, \"\") and base_link_shows_w_name[model]) or (link == \"base_link\" and not base_link_shows_w_name[model]):\n",
    "            continue\n",
    "        if not link:\n",
    "            link = \"base_link\"\n",
    "        grouped_selections[(model, link)].add((k, v))\n",
    "        \n",
    "    # Remove non-canonical if canonical exists\n",
    "    new_grouped_selections = {}\n",
    "    for (model, link), selections in grouped_selections.items():\n",
    "        has_canonical = any(parse_name(k)[\"category\"] == canonical_cats[model] for k, v in selections)\n",
    "        if has_canonical:\n",
    "            selections = [(k, v) for k, v in selections if parse_name(k)[\"category\"] == canonical_cats[model]]\n",
    "        new_grouped_selections[(model, link)] = selections\n",
    "        \n",
    "    problems = [(k, v) for k,v in new_grouped_selections.items() if len(v)>1]\n",
    "    if problems:\n",
    "        print(f\"In {fn}: {problems}\")\n",
    "    else:\n",
    "        with open(fn, \"w\") as f:\n",
    "            json.dump({k: v for selections in new_grouped_selections.values() for k, v in selections}, f, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7fbe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [\n",
    "'kqokhv',\n",
    "'oddyhd',\n",
    "'dxwbae',\n",
    "'xjyvwx',\n",
    "'cdjsgw',\n",
    "'ieyjnv',\n",
    "'saldxe',\n",
    "'xrozyp',\n",
    "'ycspus',\n",
    "'rnkvca',\n",
    "]\n",
    "\n",
    "import collections\n",
    "for fn, all_selections in files:\n",
    "    new_selections = {x: y for x, y in all_selections.items() if parse_name(x).group(\"model_id\") not in to_remove}\n",
    "    if new_selections == all_selections:\n",
    "        continue\n",
    "    with open(fn, \"w\") as f:\n",
    "        json.dump(new_selections, f, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e4e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
